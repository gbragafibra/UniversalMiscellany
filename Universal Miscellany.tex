\documentclass[12pt,  letterpaper]{article}
\usepackage{chemfig}
\usepackage[margin=1.0in]{geometry}
\usepackage{graphicx}
\usepackage{mhchem}

\title{Universal Miscellany}

\author{GonÃ§alo Braga}
\graphicspath{/home/fibra/Desktop/Universal Miscellany }

\begin{document}
\maketitle
\begin{center}


\rule{\textwidth}{0.5pt}
\begin{abstract}
\center{Whatever comes to mind that I want to understand better, rambling a bit about it.}
\end{abstract}
\rule{\textwidth}{0.5pt}	
\end{center}
\paragraph*{}
Entry 1 - 14 Oct 2021
\subsection*{Glycolysis}
\paragraph*{}
Generally we would have:
\paragraph*{}
\begin{equation}
\ce{Glucose + 2NAD+ + 2ADP + 2P_{i} -> 2pyruvate + 2NADH + 2H+ + 2ATP}
\end{equation}
\paragraph*{}
Glycolysis alone doesn't solve reliable energy "production"\footnote{This referring to free Gibbs energy,$\Delta G$, liberation, and creation of an intermediary energy holding molecule.}. If pyruvate is degraded in aerobic respiration, by oxidative phosphorylation, it will on average give about to the formation of 30-32 molecules of ATP. In this case, we would have:
\begin{equation}
\ce{C6H12O6 + 6O2 -> 6CO2 + 6H2O + 30-32ATP}\footnote{This is simplified.}
\end{equation}
\paragraph*{}
If by fermentation or anaerobic respiration, we would have the formation of just 2 ATP molecules.
\paragraph*{}
The glycolysis pathway is catalysed by 10 different enzymes, 3 of these being employed in regulation.\footnote{There is no need for heavy regulation, in respect to all enzymes, otherwise the process would become inefficient.}
We need to have in mind that the 3 reactions that rely on the regulative enzymes, are strongly exergonic, those being irreversible reactions, accounting for the 3 points of regulation on the glycolysis pathway. Also, the compromise step is number 3, being the only exclusive reaction of this pathway. 
\paragraph*{}
As an add-on we need to remember that for the sustainable production of ATP molecules to happen, we need to go further than glycolysis alone, and have the degradation of pyruvate to enable $\ce{NAD+}$ regeneration, and keep the glycolysis pathway going.
\paragraph*{}
\hrule 
\paragraph*{}
Entry 2 - 19 Oct 2021
\subsection*{Energetic transitions}
\paragraph*{}
I have a hard problem in my hands. I don't have strong backbone neither in Mathematics or Physics, and as I'm going through a Biochem degree, I feel like I'm missing a sense.
\paragraph*{}
This specifically when talking about spectroscopy technics\footnote{More generally, how can I fully understand what's going on in these biochemical systems, and furthermore manipulate them, if I don't have a reasonable understanding of Physics? You are truly missing a sense.}. I understand that when dealing with this kinds of problems, and using a quantum mechanical approach, we ought to have in our minds the concept of quantization of energy.
\paragraph*{}
For example, when talking about electronic transitions from a lower energy state ($\psi_{1}$) to a higher one ($\psi_{2}$), we ought to use UV/vis radiation as by the following relationship:
\begin{equation}
E = h \nu 
\end{equation}
where $E$ represents the energy associated with that eletromagnetic wave, $h$ being Planck's constant and $\nu$ the corresponding frequency of the wave, would have enough energy to allow us to have this kind of transition (eletronic).
\paragraph*{}
Now we should also add an energetic scale between the kinds of transitions we are reffering to. From highest energy expenditure to lowest:
\begin{equation}
Eletronic > Vibrational > Rotational > Nuclear\,spin\,reorientation
\end{equation}
However, when we irradiate a certain biomolecule with UV/vis radiation, how sure are we that this irradiation is being used to promote electronic transitions and not other types of transitions? Is it by prioritization, as we would be increasing the difference between the two energy states? Regardless, apparently these other types of transitions might be negligible in a UV/vis absorption scenario.\footnote{We would only be looking at absorptions rates dependent mostly in electronic transitions. In terms of contribuiton to absorption rates, that is to say.}
\paragraph*{}
\hrule
\paragraph*{}
Entry 3 - 20 Oct 2021
\paragraph*{}
\subsection*{Regulation of the glycolytic pathway}
We have ten reactions in the glycolytic pathway; three of those are strongly exergonic ($\Delta G << 0$), the third one being the compromise step, meaning that there's no way of going back once the products are formed. All of these three reactions are heavily regulated. How? Lets get started:
\subsubsection*{First reaction}
The reaction is given by:
\paragraph*{}
\begin{equation}
\ce{Glucose + ATP ->[Hexokinase] Glucose 6-phosphate + ADP}
\end{equation}
When product builds up (Glucose 6-phosphate), the enzyme Hexokinase starts to get inhibited. On our liver we also have on top of this enzyme, another one, glucokinase, that isn't inhibited by G-6-P. G-6-P is also used in other pathways, namely to the production of Glycogen, a small reserve of Glucose polymers that is usually stored in our liver and muscle tissue. All of this regulation and the alternation between the use of one enzyme or the other, in the liver, is used to control the normal levels of Glucose in our blood, that typically vary between $4,4-6,0\,mM$.
\paragraph*{}
\subsubsection*{Third reaction}
This reaction is given by:
\begin{equation}
\ce{Fructose 6-Phosphate + ATP ->[Phosphofructokinase 1 (PFK-1)] Fructose 1,6-bisphosphate + ADP}
\end{equation}
This is enzyme (PFK-1) is now inhibited by ATP, the final product of the glycolytic pathway, this type of regulation being characterized as feedback control. So ATP is both a substrate and an inhibitor? Yes. This enzyme is alosteric. The affinity of ATP to the inhibitor site is low, so this bond will only form at high concentrations of ATP. When we already have a high concentration of ATP, we don't need more ATP, so lets inhibit PFK-1.
\paragraph*{}
We should also add that in terms of kinetics of these reactions, when we have no inhibition, most of these reactions follow Michaelis-Menten kinetics, having an hyperbolic curve ($x$ - Substrate Concentration; $y$ - Speed of the reaction). When there starts to be inhibition this curve starts to transform to sigmoid.
\paragraph*{}
Now lets get a bit fractal. The PFK-1 enzyme is also regulated. How? We would have:
\paragraph*{}
Activators - AMP, ADP and Fructose 2,6-bisphosphate
\paragraph*{}
Inhibitors - ATP and Citrate
\paragraph*{}
Lets focus on the variation of concentration of Fructose 2,6-bisphosphate. It is regulated in the following way:
\begin{equation}
\ce{Fructose 6-Phosphate + ATP ->[PFK-1] Fructose 2,6-bisphosphate + ADP}
\end{equation}
and
\begin{equation}
\ce{Fructose 2,6-Phosphate ->[FBPase-2] Fructose 6-bisphosphate + P_{i}}
\end{equation}
This enzyme is bifunctional, as PFK-1 it adds a phosphate group, as FBPase-2 it removes a phosphate group.
\paragraph*{}
\hrule
\paragraph*{}
Entry 4 (Continuation of Entry 3) - 20 Oct 2021
\paragraph*{}
\subsubsection*{Tenth Reaction}
\paragraph*{}
This reaction is given by:
\begin{equation}
\ce{Phosphoenolpyruvate + ADP ->[Pyruvate Kinase] Pyruvate + ATP}
\end{equation}
This enzyme's concentration changes in virtue of increase of glucose concentration. This enzyme is then regulated in the following way:
\paragraph*{}
Activators - Fructose 1,6-bisphosphate\footnote{We need to remember that this metabolite is produced earlier in the glycolytic path, so we refer to this type of regulation as feed-forward.} and Phosphoenolpyruvate, this one being the substrate of the correspondent reaction, and so we refer to this type of regulation as activation by substrate.
\paragraph*{}
Inhibitors - ATP\footnote{This one is an obvious type of regulation, as if there is already a high concentration of ATP in the neighborhood, we don't need more ATP, and so there is inhibition of the correspondent enzyme.} and Alanine\footnote{This aminoacid is abundant when there is energetic content ($\varepsilon$) in the cell, this meaning that the ratio given by $\varepsilon = \frac{ATP + 0,5ADP}{ATP + ADP + AMP}$ is generally higher.}.
\paragraph*{}
Of this enzyme that are aswell various similar enzymes, defined as isoenzymes, correspondent to which organ they are generally found on.
\paragraph*{}
For example, in this case, there is an isoenzyme L that is found in the liver, and that is generally regulated by covalent modification, this type of regulation being "all or nothing" in the sense that enzymes that undergo this type of change are either left completely unfunctional or close to it when deactivated, or in the case of activation, are left a near optimal performance. Then, there is an isoenzyme M that is found in our muscle tissue and brain.\paragraph*{}
Refering back to the covalent modification, in the case of the previously mentioned enzyme, the change is done by an addition or removal of phosphate group. So we can see the actual implications that such a change might enable. 
\paragraph*{}
A curiosity, or not necessarily that but an important detail is, that the isoenzyme that is in the liver has this type of regulation, but the ones present in the muscle tissue and brain do not. Why? Lets see. If we are trying to regulate ATP production, using the reducing potential glucose has, in the liver majority of the cells don't necessarily use just glucose or derivatives as an energy source. By this, we can conclude why this type of regulation would be upon the L isoenzymes. First of all, the "liver" distributes alot of glucose, but not only that, also the type of energy source used isn't just glucose. So it can actually afford to make "mistakes" and regulate heavily the tenth step of the glycolytic pathway. Now in the muscle tissue and brain, that are heavily dependent on glucose and derivatives as an energy source, there is no affording having super strong regulation that might lead to a disfunction. We need to remember that these covalent modifications are initiated by hormone release, that will after that result in a cascade of reactions leading to the correspondent covalent change. These types of events are in the scale of seconds-minutes, and will essentially overwrite any type of local influence these enzymes will at the time be influenced and predisposed to. If there was such a type of regulation appearing in any nervous tissue troughout the animal kingdom, such "fortunate" species would be pressured out the evoluotinary race. They simply can't compete with others, when they have such an expensive handicap.
\paragraph*{}
\hrule
\paragraph*{}
Entry 5 (Continuation of Entry 1) - 20 Oct 2021
\paragraph*{}
Just an add-on, when reffering to the regeneration of $\ce{NAD+}$, such a step is not need in aerobic respiration. However, when talking about anaerobic respiration, we would need to go fully comitted to fermentation (either lactic or alcoholic, major ones), to actually regenerate $\ce{NAD+}$.
\paragraph*{}
\hrule
\paragraph*{}
Entry 6 - 21 Oct 2021
\subsection*{Nervous impulses and related events}
\paragraph*{}
It is perhaps a bit too limited to say we (humans) are for the most part creating formidable technology, revolutionary indeed. While this is true, we should back up a bit and watch the impressive complexity already "developed". While I'm rambling a bit, I think the label "Technology" is too limited, even with the more specific parts like Biotech. We are on the start of a really good road to achieve not only "immortality"\footnote{Let us define this as just reaching longevity escape speed.}, but also be able to understand Nature to a level where we can cooperate with it and change our neighborhood in accordance to our likes, obviously taking into account the presumed consequences.
\paragraph*{}
This ramble is very vague, however how can you describe something so beautiful without losing your words, and creating a bit of an incoherent speech.
\paragraph*{}
When you imagine computing and more generally, information processing systems, you would perhaps refer to digital, some other mechanical types, and even to a more complex scope, physicochemical leverages of computation. And then you get to an emergent type, the biological one.
\paragraph*{}
Making this kind of division between frameworks isn't necessarily the best, when it comes to this and other cases.
When you look at it, it is just computing. It's all there is; information processing.
\paragraph*{}
Lets focus on a simple system of communication and afterwards integration, between two clasical neurons.\paragraph*{}
There are broadly defined two types of "communications":
\paragraph*{}
\textbf{Chemical Synapses}
\paragraph*{}
and
\paragraph*{}
\textbf{Eletrical Synapses}
\paragraph*{}
While this might be wonderful to evaluate a student's commitment to memorization of definitions, these are pretty much the same thing, just a little bit different. Their names don't make easy formation for intuition.\paragraph*{}
With a chemical synapse, you have the delivery of neurotransmitter encapsulated in a vesicle, from one pre-synaptic terminal from a first neuron to the dendrites of the next neuron. This vesicle will therefore be degraded in the next cell with the appropriate enzymatic machinery, releasing the neurotransmitter that will bind to a certain receptor, leading to a cascade of other chemical reactions, eventually propagating the "nervous impulse"\footnote{We will get back to what this means.}.
\paragraph*{}
The eletrical synapse is considerably faster, because there is a link between the two adjacent neurons, formed by channels that bridge the gap, named gap junction. This will alow the movement of charges from one neuron to the other, essentially propagating the "nervous impulse".\footnote{Should also add that this is bidirectional.}
\paragraph*{}
\hrule
\paragraph*{}
Entry 7 (Continuation of Entry 6) - 22 Oct 2021
\subsubsection*{Describing eletrical impulses between neurons}
First of all, I'm not necessarily sure if I can describe the kind of communication that happens between neurons as an eletrical impulse, atleast in the same way when we are talking about electricity.\paragraph*{}
For this kind of definition to be atleast related, we would be talking about electron conduction, from one end of a neuron to the other, where perhaps some of the electrons would create conformational changes in some receptor, leading to a cascade of reactions propagating the "signal".
We don't have that, atleast in the scope we are interacting with this two neuron system.\paragraph*{}
But how does it work? How does it get started?
\paragraph*{}
All neurons that aren't excited have what is called a resting potential. We will be talking in the scale of $mV$ for all these events. Extracellular environment has a $+mV$ value for electric tension in this state, while intracellular one has a $-mV$ value. The bigger (in this case positive) the value of eletric tension is, the better you can conduct charges. We are obviously not getting anywhere if the eletric tension between two points doesn't change along a certain period of time. That would mean, the propagation of this signal wouldn't happen, or would be conflicted and happen in a chaotic way.\paragraph*{}
We should also refer that in this state, in the intracellular environment there is a:
\paragraph*{}
Big concentration of $\ce{K+}$
\paragraph*{}
Small concentration of $\ce{Na+}$
\paragraph*{}
Small concentration of $\ce{Cl-}$
\paragraph*{}
Proteins charged negatively
\paragraph*{}
and a reasonable concentration of Organic Ions.
\paragraph*{}
In the extracellular environment this is reversed. There is still charge neutrality overall, and so this kinds of eletric tension gradients would be caused by the motion of a small number of ions. Here you start to see what's capable. This is state, like every system related to biological phenomena, is regulated by the likes of: selectrive permeability of the cellular membrane to $\ce{K+}$; incapability of motion of these big anions and proteins of leaving the cellular environment without active transport; and the action of potassium-sodium pump\footnote{This one, is obviously in the category of active transport, taking 3 $\ce{Na+}$ outside the cell for every 2 $\ce{K+}$ that get in. Both actions need an energy input, as they are going against concentration gradients.}.
\paragraph*{}
Now lets get started in the emergence and propagation of the electric signal. What we are about to describe is called the depolarization event, where the intracellular and extracellular eletric tensions are inverted.
\paragraph*{}
If there is a certain input, like the release and binding of a compound to ion channel\footnote{Specifically, $\ce{Na+}$ ones.}, opening, closing or inactivating the respective channel, it will trigger a local change of eletric tension. This will lead to the betterment of conduction of negative ions along the axon. We have to take into account that there are voltage dependent channels, that will inherently be inactivated once the "action potential" goes by. Here we actually see the "conduction" part.\paragraph*{}
Once it "goes by" we start the repolarization event, getting  the resting potential back.\paragraph*{}
Now wait a minute. I see every type of modern appliance with a classic insulator, basically restricting the influence the electric field would have on the electrons to one dimension. Of course signal transduction would be very inneficient without some type of insulation. Let yourself be introduced to the concept of myelination. Majority of the axons are myelinated with small gaps in between each myelin sheat. These gaps are called Nodes of Ranvier. The purpose of these nodes, has to do with its exposed nature to the extracellular environment, basically allowing diffusion of ions, contributing to the regeneration of the electric impulse. This electric impulse will eventually arrive at	an axon terminal, where through the enzyme machinery will be propagated to the post-synaptic cell.\paragraph*{}
\hrule
\paragraph*{}
Entry 8 - 25 Oct 2021
\subsection*{UV/vis absorption and electronic transitions}
When talking about this kinds of events, we can generally apply, for approximately linear molecules, the Particle in a Box model. We would have the energy for the correspondent energy state as:
\begin{equation}
E_{n} = \frac{\hbar^{2}\pi^{2}n^{2}}{2a^{2}m_{e}} = \frac{h^{2}n^{2}}{8a^{2}m_{e}}\,, n = 1,2,3...
\end{equation}
where $h$ is Planck's constant, $n$ the correspondent energetic state, $m_{e}$ the mass of the electron, and $a$ the size of the chromophores\footnote{Chromophores are the groups in a molecule that absorb light.} in that respective molecule.
\paragraph*{}
For electronic transitions in UV/vis we are for the most part only talking about the following transitions: $\pi \rightarrow \pi^{*}$ and $n \rightarrow \pi^{*}$.
\paragraph*{}
For an ethylene molecule we have one double bond, and so HOMO\footnote{Highest Occupied Molecular Orbit.} can only be $\pi$ and LUMO\footnote{Lowest Unoccupied Molecular Orbit.} the $\pi^{*}$. However how do we define HOMO and LUMO, for example, for $\beta$-carotene, that has $11\,\pi$ orbitals?
\paragraph*{}
We will need to define $N$ as the energetic state for HOMO, and $N+1$ as the energetic state for LUMO. In this case, we will have:
\begin{equation}
\Delta E = E_{N+1} - E_{N} = \frac{h^{2}}{8a^{2}m_{e}}(2N+1)
\end{equation}
With this we can also calculate the wavelenght of the radiation needed to create such an electronic transition:
\begin{equation}
\Delta E = h\frac{c}{\lambda} = \frac{h^{2}}{8a^{2}m_{e}}(2N+1) \Leftrightarrow \lambda = \frac{8a^{2}m_{e}c}{h(2N+1)}
\end{equation}
The bigger the chromophores size the bigger wavelenghts the electronic transitions will be at, and bigger absorptions spikes at those correspondent wavelenghts.	
\paragraph*{}
\subsubsection*{Hypochromism}
If we think about electronic transitions, once an electron leaves from a HOMO to a LUMO there will be charge gradient. We can also represent it as a transition dipole moment vector. Classicaly it is represented as vector from the higher electron density ($\delta^{-}$) to a lower electron density ($\delta^{+}$). However, we can easily just think about electron movement, and the need of other neighborhood dipoles to adjust for that. When we are talking about parallel dipoles, if there is an electronic transition from a HOMO to a LUMO, neighborhing dipoles, in this case chromophores, will be less likely to go through such electronic transition as they have already adjusted to such charge gradient, it will be unfavourable for another electron to go from a HOMO to a LUMO. Dipole-Dipole interactions are only really efective at $R \leq 5\,\AA$.
\paragraph*{}
Now we start seeing a better picture of what's going on. When we are talking about double-stranded DNA, or just polynucleotides in solution, which case is going to have a bigger absorption rate at a specific wavelenght? Obviously, the fragmented one, because the fragments are separated enough as to not influence others through dipole-dipole interactions. In a double-stranded DNA molecule, parallel bases are distanced by about $3,4 \AA$, enough to let this dipole-dipole interactions to take hold, driving a smaller probability of electronic transitions, leading to smaller absorption spike.\paragraph*{}
Must also add, that in hyperchromism (bigger absorption) we have the opposite, it's almost defined as a positive-feedback loop, as the transition dipole moment vectors are perpendicular to each other. We don't talk much about hyperchromism, because there aren't a lot of examples of biomolecules that would inherent such beheaviour. Still important to understand this mechanism though.
\paragraph*{}
\subsubsection*{What if we smash a cell?}
What about this scenario? What do I do, when we have unknown concentrations for proteins, nucleic acids and so on. Well, we atleast know that for a specific wavelenght, that absorption signal is the sum of all the individual absorptions for all the compounds present in that solution. Lets just take DNA and proteins, as the compounds. And lets do the absorption reading at $\lambda = 260\,nm$. We would have:
\begin{equation}
A_{260} = \varepsilon_{DNA}^{260}C_{DNA}l + \varepsilon_{Protein}^{260}C_{Protein}l
\end{equation}
However, we have two variables that we don't know; $C_{DNA}$ and $C_{Protein}$. So, we need another absorption reading. For example at $\lambda = 280\,nm$. Now we would also have:
\begin{equation}
A_{280} = \varepsilon_{DNA}^{280}C_{DNA}l + \varepsilon_{Protein}^{280}C_{Protein}l
\end{equation}
leading to equation system, that is solvable for $C_{DNA}$ and $C_{Protein}$.
\paragraph*{}
If we are talking about purification analysis, we would have:
\paragraph*{}
$$\frac{A_{260}}{A_{280}} \simeq 1,8$$ , we consider DNA pure	.
\paragraph*{}
$$\frac{A_{260}}{A_{280}} \simeq 2$$ , we consider RNA pure	.
\paragraph*{}
$$\frac{A_{260}}{A_{280}} \simeq 0,57$$ , we consider protein pure	.
\paragraph*{}
\subsubsection*{Isosbestic points}
If we are reading absorption rates for the same protein, for example, however doing different readings for an environment change, such as pH, and we find a point where the absorption is the same for two different scenarios for the same protein, we call that an isosbestic point. If we are in the presence of 2 or more isosbestic points, then we can conclude that this protein has 2 types of conformations atleast. Does that make sense? If they have same absorption, that means that they locked into a specific conformation. That's the only way an isosbestic point emerges. So, indeed it makes sense.
\paragraph*{}
\hrule
\paragraph*{}
Entry 9 - 27 Oct 2021
\subsection*{Gluconeogenesis}
Gluconeogenesis is the inverse pathway of glycolysis, and for vertebrates happens mainly in the liver, and to a very small extent in the kidneys. The "purpose" of this pathway is to synthesize glucose. A lot of substrates used to create glucose, not being sugars, are lactate, pyruvate and aminoacids. 
\paragraph*{}
As we already know, when talking about regulation mechanisms and metabolic pathways in general, there are no contradictions, as organisms where metabolic contradictions would emerge, would quickly be pressured out the evolutionary race. These two pathways, glycolysis and gluconeogenesis are inter-regulated, in the sense, that when gluconeogenesis is stimulated, glycolysis will be repressed, and vice-versa.
\paragraph*{}
When is gluconeogenesis activated?
\paragraph*{}
This generally happens when the organism is fasting, during prolonged exercise, and when its diet is poor in carbohydrates. Mammals don't turn fat into glucose. What happens is that, glycerol that is derived from lipid degradation can be turned into glucose. However, as we remember glycerol is only a very small part of lipid molecule, this being a very unreasonable way to produce glucose.\paragraph*{}
We remember from the glycolytic pathway, that we had 3 strongly regulated reactions, and so the enzymes associated with those reactions are obviously exclusive to glycolysis, as it doesn't make sense for an enzyme to catalyze two reactions that have contradictory functions as a whole, in terms of cell energetics. Following this train of thought, gluconeogenesis is going to have 3-4 strongly regulated reactions, with their exclusive enzymes.\paragraph*{}
For reactions 1 and 2 of gluconeogenesis, that would match out reaction 10 in the glycolytic pathway, we have the use of pyruvate carboxylase (PC), this enzyme being exclusively mitochondrial, and the use of phosphoenolpyruvate carboxykinase (PCK). For reactions 8 and 10 of gluconeogenesis, we have the use of fructose-1,6- bisphosphatase (FBPase) and glucose-6-phosphatase (GPase), respectively. Must also add, that in organs that don't have gluconeogenesis there is no GPase enzyme. All the other 7 enzymes are shared between pathways, as those reactions are reversible. All the reactions happen in the cytosol, except for the one needing the PC enzyme, as it is exclusively mitochondrial.
\paragraph*{}
But wait a minute, when we are converting pyruvate into glucose, we are using 2 pyruvate molecules for glucose production, and needing 6 ATP. Not efficient? We need to remember that we need to mantain a stable amount of glucose in the blood, for sustainable distribuition through our tissues. Those cells, there on can perform oxidative phosphorylation, resulting in about 30-32 ATP. So it is not necessarily about efficiency. We are trying to mantain a robust web of glucose distribuition, so our tissues don't degenerate.
\paragraph*{}
\hrule
\paragraph*{}
Entry 10 - 28 Oct 2021
\subsection*{Glycogen degradation and synthesis}
Lets think about how glucose reserves, in the form of glycogen, are used and reset. Glycogen then is described as being ramified polymer of D-Glucose. As said before, these reserves exist mainly in the liver and muscle tissue.
\paragraph*{}
Dwelling a bit about glycogen structure. Why is it ramified? Well, when we are thinking about sugars, they are only reducing ones, if the anomeric carbon is available. For glucose that corresponds to C-1. So, when thinking about the best way to remove and put back glucoses in this structure, the most viable way is to have a lot of available points, i.e. ramification.
\subsubsection*{Very general description of glycogen degradation and synthesis}
\paragraph*{}
\textbf{Glycogenolysis}
\begin{equation}
\ce{Glycogen_{(n\,residues)} + P_{i} ->[Glycogen phosphorylase] Glycogen_{(n-1\,residues)} + Glucose-6-phosphate}
\end{equation}
\paragraph*{}
\textbf{Glycogenesis}
\begin{equation}
\ce{Glycogen_{(n\,residues)} + Glucose-6-phosphate + ATP ->[Glycogen synthase] Glycogen_{(n+1\,residues)} + ADP + P_{i}}
\end{equation}
This are very general descriptions of these pathways. As we will see they are way more complex. Must also add that these two enzymes are obviously regulated by allostery and covalent modifications.
\paragraph*{}
Yet again as said before, glucose reserves in the liver, when fasting, are used to mantain reasonable levels of glucose in the blood. In the muscle tissue, however, these are used when there is a bigger intensity. Fermentation starts to occur. Even if there is lower yield of ATP, it is actually faster than aerobic respiration, and in this case that's what's needed. \paragraph*{}
A "small" detail is that after eating, the liver can rebuild glycogen, when glucose levels are high in blood, even if hexokinase is already inhibited by glucose-6-phosphate. This is because, the liver has its own enzyme, glucokinase, which has a lower affinity for glucose-6-phosphate as an inhibitor, and will essentially decrease in activity way later, compared to the case of hexokinase.\paragraph*{}
This is a very general description, and will probably be a bit developed in the future.
\paragraph*{}
\hrule
\paragraph*{}
Entry 11 - 28 Oct 2021
\subsection*{Redox reactions and the recharging of a conventional battery}
What does actually happen when we are recharging a phone battery, or any similar modern appliance?
\paragraph*{}
Lets actually start with how galvanic cells work.
\paragraph*{}
You generally have three main components of such a system. An anode where an oxidation reaction happens, a cathode where the reduction reaction happens, and one saline bridge neutralizing the charges given into solution in each side. In the anode side, there would be oxidation and so the saline bridge on that side would give anions into solution. In the cathode side, precisely the opposite happens.
\paragraph*{}
Lets give a general outlook into such a system. Taking the following as an example:
\begin{equation}
\ce{Zn(s) + Cu^{2+}(aq) -> Cu(s) + Zn^{2+}(aq)}
\end{equation}
This equation can be further divided into 2 other semiequations to give us a better picture of what's happening, if that wasn't already apparent:
\begin{equation}
\ce{Zn(s) -> Zn^{2+}(aq) + 2e^{-}}
\end{equation}
and 
\begin{equation}
\ce{2e^{-} + Cu^{2+}(aq) -> Cu(s)}
\end{equation}
Both bars, these represented by Zn and Cu in the solid state are envolved in liquid $\ce{SO_{4}^{2-}}$, giving emergence to a solution of $\ce{ZnSO_{4}}$ and $\ce{CuSO_{4}}$, respectively.
\paragraph*{}
And through all this process, what's happening is electron conduction from the anode to the cathode, that can be measured in Voltage by a Voltimeter.\paragraph*{}
If this reaction is not in equilibrium, then the direct reaction can be spontaneous or not. If $E_{cell}^{0} > 0$, then the reaction is spontaneous. If $E_{cell}^{0} < 0$, then the reaction is not spontaneous. And obviously if $E_{cell}^{0} = 0$, we are in equilibrium.
\paragraph*{}
If the direct reaction is spontaneous, then the reverse is not, and for it to happen needs an energy input. 
\paragraph*{}
Ok, we are getting somewhere.
\paragraph*{}
Lets take it to final point. How does battery recharge happen?
\paragraph*{}
When we are for example using a phone and battery power keeps going down, we are witnessing the direct reaction happen, it being spontaneous. All the electron flow, or if you will, electricity, is provided to aid in all logical circuits implemented in the phone, to get to its desired function.\paragraph*{}
Now, when you are out of power, when your battery is dead, what do you do? You will in this case, supply energy to the battery, so the reverse reaction happens, replenishing the desired concentrations so to make the direct reaction spontaneous. You link your phone to the power grid, and through intricate electron movement, you make your phone usable again for the next howmanyever hours. Indeed interesting.\footnote{On a side note, I will probably revisit this, atleast thinking a bit about biocells. This is because, recently I read that you have about 50\% efficiency in terms of energetic production in these biocells and biogenerators, compared to the 30-40\% available to classic heat engines. Atleast methods used rely on bacteria that instead of using $\ce{O_{2}}$ as an electron acceptor, they rely on other metals.}
\paragraph*{}
\hrule
\paragraph*{}
Entry 12 - 29 Oct 2021
\subsection*{Equilibrium constants and reaction rate constants}
Lets generalise this analysis, and say that we have the following reaction:
\begin{equation}
\ce{A + B <=>[k_{1}][k_{2}] C + D}
\end{equation}
where $k_{1}$ and $k_{2}$ are reaction rate constants, that are generally represented by:
\begin{equation}
k(T) = Ae^{\frac{-E_{a}}{RT}}
\end{equation}
where $A$ is a frequency factor, $E_{a}$ the activation energy, $R$ the perfect gases constant, and $T$ temperature.
\paragraph*{}
Eventually, you would get a reaction rate given by:
\begin{equation}
r = k(T)[A]^{m}[B]^{n}
\end{equation}
where m and n are partial orders refering to [A] and [B], respectively.
\paragraph*{}
You can clearly see the temperature dependence of reaction rates.
\paragraph*{}
Lets go to equilibrium constants. In this case, it will be given as:
\begin{equation}
K_{eq} = \frac{[C][D]}{[A][B]}
\end{equation}
where $[\chi]$ represents the correspondent concentration of each compounds at equilibrium time. And this equilibrium constant is specific to each temperature. How? Lets see.
\paragraph*{}
We have to remember the following considerations:
\begin{equation}
\Delta G = \Delta H - T\Delta S
\end{equation}
\begin{equation}
\Delta G = -RTln(K_{eq})
\end{equation}
With this, we can create the following equality:
\begin{equation}
\Delta H - T\Delta S = -RTln(K_{eq})
\end{equation}
and so we would have:
\begin{equation}
ln(K_{eq}) = \frac{\Delta S}{R} - \frac{\Delta H}{RT}
\end{equation}
We clearly see the temperature dependence of equilibrium constants. However, what's actually going on? Lets see.
\paragraph*{}
Two categories; endothermic and exothermic reactions.
\paragraph*{}
For exothermic reactions ; $\Delta H < 0$
\paragraph*{}
For endothermic reactions ; $\Delta H > 0$
\paragraph*{}
and so, if temperature, for example, goes down and we want to mantain the same equilibrium constant, we need to reduce $\Delta H$ and so favor the exothermic reaction.
\paragraph*{}
If temperature is increased, it is precisely the opposite. We need to increase $\Delta H$ to mantain the same equilibrium constant and so, favor the endothermic reaction.
\paragraph*{}
We don't even need such a quantative analysis about such systems. We can only imagine that with temperature gradients, these compounds are going to behave in a different way, acquiring different energy states, and so leading us to a different proportion of concentrations at equilibrium time.
\paragraph*{}
If we want a more precise notion of what's going on, there is the Van 't Hoff equation, that relates two equilibrium constants at different temperatures, if we know the standard enthalpy change:
\begin{equation}
ln(K_{2}) = ln(K_{1}) - \frac{\Delta H^{\ominus}}{R}\left(\frac{1}{T_{2}}-\frac{1}{T_{1}}\right)
\end{equation}
\hrule
\paragraph*{}
Entry 13 - 31 Oct 2021
\subsection*{Thinking about entropy}
Lets ignore the vague notion of entropy measured in terms of the disorderliness of a respective system.
\paragraph*{}
Lets think about it in terms of information.
\paragraph*{}
Lets assume some statements for entropy:
\paragraph*{}
\textbf{1 - Each $i^{th}$ microstate has a probability $P_{i}$ assigned.}
\paragraph*{}
\textbf{2 - If $P_{i} = 0$, the respective state has no contribuition.}
\paragraph*{}
\textbf{3 - If any $P_{i} = 1$, then total entropy is zero.}
\paragraph*{}
\textbf{4 - All of the possible states have a contribuition, and so entropy is given by the sum over states.}
\paragraph*{}
With this we can generalise, and say that entropy is given by:
\begin{equation}
S = -k_{b}\sum_{i} P_{i}log(P_{i})
\end{equation}
We have the Boltzmann constant here, so as to have $J/K$ units for entropy.
\paragraph*{}
Now wait a moment, if we look at the way we though about the staments we made, we would realise, that this is the case where we can't notice distinctions between each microstate. If we could, and for each and every microstate, there would be an equal probability assignment, then entropy would be given as:
\begin{equation}
S = k_{b}log(\Omega)
\end{equation}
where $\Omega$ is the number of states, also said to be the multiplicity of the system.\paragraph*{}
We can notice what's going on as:
\begin{equation}
S(\Omega) = \lim_{\Omega\to\infty} k_{b}log(\Omega) = \infty
\end{equation}
and that makes perfect sense. There's going to be an increase of entropy, as there is an increase of the total amount of states available.
\paragraph*{}
Now when tackling the information correlation, we need to realise that we are using properties of microstates such as:\paragraph*{}
\textbf{Position}
\paragraph*{}
\textbf{Momentum}
\paragraph*{}
\textbf{Kinetic Energy}
\paragraph*{}
to approximate to a macrostate, that has properties such as:
\paragraph*{}
\textbf{Temperature}
\paragraph*{}
\textbf{Pressure}
\paragraph*{}
\textbf{Density}
\paragraph*{}
Now we can understand the correlation. The bigger the entropy, the bigger the amount of information related to microsates we left behind to actually describe the macrosate.
\paragraph*{}
\hrule
\paragraph*{}
Entry 14 - 2 Nov 2021
\subsection*{What the hell is going on?}
This is going to be me just ranting.
\paragraph*{}
I'm actually missing a sense. I can't understand reasonably how fundamental particles behave, so I can't actually understand what is going on in these biochemical systems.
\paragraph*{}
I have an extreme difficulty visualizing, and therefore trying to predict, what is actually going to happen, in these semi-microscopic biochemical systems. I don't know how photons, electrons and so on, behave. I have an idea, but just that. And majority of the times, I'm dead wrong, about my predictions. This is what I meant about getting physics undergraduate degree. Not necessarily that, but getting to that reasonable level of understanding. I need to pickup a physics textbook, and really try to understand what's going on. I must say that majority of what I find counterintuitive, stems from the wave-particle duality.
\paragraph*{}
And this is only the start, because I can ramble for hours and hours on end, about things I do not understand. I will probably do that in the following $n^{th}$ entries.
\paragraph*{}
\hrule
\paragraph*{}
Entry 15 - 3 Nov 2021
\subsection*{Nuclear magnetic resonance (NMR) spectroscopy}
This is just a quick entry, mainly dealing with analysing which protons might actually have their spin altered. For their spin to be altered, they need to be exposed to a specific magnetic field. Particles that are "shielded" in a molecule or atom, are less likely to have their spin altered, because they need a magnetic field with bigger intensity. In this case, they might be "shielded" by other electrons, them being an influence on how that specific particle will perceive the main magnetic field.\paragraph*{}
Now, lets take the example of methanol ($\ce{CH3OH}$). Which proton will most likely have his spin altered? Obviously the proton correspondent to the hydrogen bonded to oxygen. Oxygen being a more electronegative atom than hydrogen, will have a bigger probability for electrons to be around it, instead of the hydrogen atom. In this case, this hydrogen isn't very much "shielded" as the other ones, and will need a less intensive magnetic field, to actually have its spin altered.
\paragraph*{}
\hrule
\paragraph*{}
Entry 16 - 4 Nov 2021
\subsection*{How does light actually behave?}
This will for sure take a while to actually nail down. What I'm refering to, is understanding how light behaves reasonably, and to other extents, fundamental particles, like electrons.
\paragraph*{}
When we refer to a certain radiation-matter interaction, taking as an example refraction, what's actually happening?
\paragraph*{}
We refer to a refraction index ($\eta$), as a property a certain material has, this one being limitant on the speed of radiation in that environment. What I can only presume is that, this is a very macroscopic aproximation. It works in optics, when we try to predict the angle the refracted light will have. However, when we think about what's happening, I don't even know how to approach it. \paragraph*{}
Radiation still has the same speed, as in vacuum ($c$), individual photons still travel at that speed. I would think $\eta$ is actually a ratio between the number of photons that get through and the number of photons emited. Generally, as denser the material, the less the number of photons will actually get through.\paragraph*{}
And I don't even think you could generalise so much, as dependent of the actually wavelenght of the incident radiation, the atoms and molecules composing that material, would behave differently, leading to other types of phenomena, as for example, photon reemission, scattering, and so on.\paragraph*{}
Is this difference so small, we can assume it is negligble? It kinda appears to be so.
\paragraph*{}
Right now in physical biochemistry, I'm going through polarization of light for application in biochemical systems.\paragraph*{}
If we generalise, as an example, a specific solute containing a molecule of both chiralitys L and R, polarized light, in this case circulary polarized, will probably behave differently, leading to a retardation in the components of the electromagnetic vector of the correspondent radiation, in either case of L or R chiral molecules. And so in the end, we will have $\eta_{L} \neq \eta_{R}$. The angle of rotation of the plane of polarization of light is given as:
\begin{equation}
\alpha = \frac{\pi}{\lambda}(\eta_{L} - \eta_{R})d
\end{equation}
where $d$ is the path light travels.
\paragraph*{}
What boggles my mind, is that apparently the wavelenght of the radiation that got retarded, is apparently the same? 
\paragraph*{}
Does the conservation of energy principle no longer apply? I really doubt that. Even if the retardation of one of the components of the electromagnetic vector didn't need an energy input, why then is $\eta_{L} \neq \eta_{R}$?\paragraph*{}
I understand my ignorance, and I'm probably missing something here, however at a first glance, there seems to be a pretty blurry bridge between macroscopic and microscopic conceptualization of these kinds of interactions.
\paragraph*{}
\hrule
\paragraph*{}
Entry 16 - 11 Nov 2021
\subsection*{De Broglie wavelength of biological molecules}
\paragraph*{}
If we consider:
\begin{equation}
\lambda = \frac{h}{p} = \frac{h}{mv}
\end{equation}
for an electron, which casually has a speed of a fraction of the speed of light, $c$, lets assume $v = 3,00\,\times\,10^{7}\,m/s$, and $m_{e} = 9,11\,\times\,10^{-31}\,kg$, we would have:
$$\lambda_{e} \simeq 2,42\,\times\,10^{-11}\,m$$
which is pretty significant. However, we already had this notion, that electron will have a significant wave-particle behaviour at this scales. Lets now take another example.
\paragraph*{}
Lets take the example of hemogoblin, which has $M \simeq 64,5\,g/mol$. So, one hemogoblin will have mass, $m_{hem} = 1,07\,\times\,10^{-25}\,kg$. We will consider the average speed of molecules in a cellular scenario to be, $v = 340\,m/s$. So we will have:
$$\lambda_{hem} \simeq 1,82\,\times\,10^{-11}\,m$$
We clearly made very big assumptions, however, this is still relevant. Although, being a fraction of the actual size of the protein, it still needs to be considered for visualization purposes. Needs to be refered, that this is a gross oversimplification, I presume we are not even taking into account relativistic scenarios, if those need to be in place, at this biochemical level.
\paragraph*{}
\hrule
\paragraph*{	}
Entry 17 - 11 Nov 2021
\subsection*{Absorption interactions}
\paragraph*{}
When we are reffering to absorption, and the excitation of an electron from $E_{1}$ to  $E_{2}$, there will be an emergence of an electric dipole. This electric dipole, if at dipole-dipole interaction range ($r \leq 5,0\,\AA$), will interact with the neighboor's magnetic component, essentially dephasing their electromagnetic vector. This will be good if there is a polarized light interaction, because in that case, both electromagnetic vectors are phased between eachother, and reeinforce the interaction\footnote{When I say "both", I'm reffering to the incident photon electromagnetic vector, and the correspondent moving electron generated electromagnetic vector.}. When we say, that dipole-dipole interactions don't favour absorptions rates, that is because the favored part, that will be phased, is almost neglible in comparison to the interactions that are dephased. And so, generally at $r \leq 5,0\,\AA$, we have:
\paragraph*{}
\textbf{Decrease of absorption, relative to non polarized light.}
\paragraph*{}
\textbf{Increase of absorption, relative to polarized light.}
\paragraph*{}
\hrule
\paragraph*{}
Entry 18 - 6 Dec 2021
\subsection*{Rant number n+1}
\paragraph*{}
As I said before, I'm currently enrolling in biochemistry undergraduate studies. And while I do think I have a reasonable interest in biochemical systems and how they emerged, I still feel like there is so much missing. Not only the approach, which seems completely systematized, leading to a very "inorganic" view of what's going on around us, but also an almost opposition to mathematical and physical intuition building to model for everything around us. It's almost a cultural problem. There's an aversion to problem solving, and too much of a focus on details, which for the most part are useless, if not applied to actual problem solving. Everything seems to be about optimization, in a grading sense. But who actually cares? Does that lead to a better scenario about understanding Nature? I don't think so.\par 
Some of this might stem from the fact that I'm very erratic. My interests fluctuate quite a bit, and as such I would like to follow them as best as I can. Unfortunately, majority of the time I can't do that. Regardless, I feel like majority of people aren't trying to understand how Nature works, in these "instituitons". If everything eventually comes down to metrics, are these metrics really that useful? Can anyone really blame them? If metric obcession, leads to a better probability of actually thriving, why not do it?\par 
I just hope that along this journey I don't actually lose the motivation behind what I'm doing, which is for most part just having fun and trying to understand how Nature works.\par 
Imagine actually turning cynical over all of this, taking it too seriously, when you're experiencing the most beautiful and sublime event anyone has seen; the emergence of what anyone can call: the biggest and most sublime cosmic joke. Have fun, and remember, this brief existence only lasts a "bit" if you want so, conquer and understand Nature and you might have a shot at actually becoming the stand-up comedian who wrote this hilarious joke.
\paragraph*{}
\hrule
\paragraph*{}
Entry 20 - 28 Dec 2021
\subsection*{Diffusion}
I was wondering about diffusion, and even more specifically when refering to biochemical scenarios, and couldn't necessarily make the connection.\par It is, I would say actually very simple.\par 
If we have two compartments, A and B, $[A]>[B]$, regardless of what happens, as molecules perform a random walk, they essentially are travelling in all directions. If there is a bigger amount of molecules in compartment A, then there is going to be a net travel of molecules from A to B, even though there are still molecules travelling from compartment B to A.\par 
In a biochemical scenario, for the most part there is a semipermeable membrane, that doesn't let all solute go through\footnote{Let me say, I don't like the distinctions solute and solvent too much, as they lead to too much of an abstraction, almost losing grip of what's going on in the cell.}, and in this case through random walks, if we have an hypertonic cellular environment, "the water is going to follow the solute". Lets just clarify this terrible description.\par 
As kids, this is the first thing you are introduced to, when talking about cellular mechanisms, and let me say, it is perhaps a mistake. Not only, as a kid, don't you take the material very seriously, and are just goofing off, not having too much of an inquisitive spirit for the most part, but also, you are forming an idea of how reality works that isn't necessarily true.
\par 
A better way to put it would be:
\par 
We have a semipermeable membrane that doesn't every type of molecule diffuse through to and out of the cell. Taking that into account, we have an hypertonic intracellular environment, and as such it is implied there is a bigger amount of water outside the cell than in the inside. With this in mind, it is only through a trivial probability outcome, that we find that a bigger amount of molecules of water diffuse into the cell, than out of the cell, leading to the legendary expression, "the water follows the solute".\par 
It must be said, that this was at best a qualitative analysis, and for example, you might be able to amplify what's going on, considering changes in the enthalpic and entropic factors, by:
\begin{equation}
\Delta G = \Delta H - T\Delta S
\end{equation}
\paragraph*{}
\hrule
\paragraph*{}

\end{document}